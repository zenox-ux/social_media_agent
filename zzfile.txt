

# --- Imports ---
import os
import requests
from typing import TypedDict, Optional, List, Dict
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
import re
import json
import tweepy
import praw
import google.generativeai as genai
import random
from PIL import Image
from io import BytesIO
import time
import streamlit as st
from app import (
    find_relevant_subreddits,
    search_and_filter_posts,
    scrape_validated_posts,
    generate_report_from_posts,
    scrape_and_format_content,
    generate_post_function,
    extract_images_from_firecrawl,
    get_best_image_from_candidates,
    post_to_reddit,
    scrape_and_format_content,
    extract_images_from_firecrawl,
    get_best_image_from_candidates,
    save_report_to_file,
    save_raw_data_to_file
)

from database import(
    create_user,
    verify_user,
    get_latest_report,
    save_chat_message,
    get_chat_history,
    save_research_report
)


# --- Load environment variables ---
print("--- [CONFIG] Loading environment variables...")
load_dotenv()

# --- API Key Checks ---
# (Your existing key checks are perfect and remain here)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# ... etc.
print("--- [CONFIG] Environment variables loaded.")

# --- Type Definitions ---
class AgentState(TypedDict):
    generated_text: str
    url: Optional[str]
    scraped_content: Optional[str]

# ==============================================================================
# --- CORE WORKFLOW FUNCTIONS ---
# ==============================================================================

def execute_reddit_research_workflow(user_id: str, topic: str, question: str) -> str:

    """Handles the entire Reddit research process and returns the final answer."""
    print("\n" + "="*50)
    print("--- üöÄ WORKFLOW START: Reddit Research ---")
    st.info(f"üìö Starting research on Reddit for topic: '{topic}'...")
    report = None
    report_id = None
    
    with st.spinner("üß† Checking for your most recent research report..."):
        found, latest_report = get_latest_report(user_id)
        found = bool(found)
        print(type(found))
    print(f"--- [CACHE CHECK] Found recent report: {found}, Topic: {latest_report['topic'] if found else 'N/A'}")

    if found:
        print(f"--- [CACHE CHECK] Found a recent report on topic: '{latest_report['topic']}'")
        with st.spinner("ü§ñ Asking AI if the existing report is relevant to your new question..."):
            # Configure Gemini
            GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
            if not GEMINI_API_KEY:
                raise ValueError("GEMINI_API_KEY not found in .env for relevance check.")
            genai.configure(api_key=GEMINI_API_KEY)
            model = genai.GenerativeModel('gemini-1.5-flash-latest')

            # Prompt to check relevance
            relevance_prompt = f"""You are a relevance analysis expert. Determine if an existing research report is sufficient to answer a new user question.

            **Existing Report Topic:** "{latest_report['topic']}"
            **Existing Report Summary (first 1000 chars):**
            ---
            {latest_report['content'][:1000]}...
            ---
            **New User Question:** "{question}"

            Can the new user question likely be answered using the existing report?
            Respond with ONLY a single, raw JSON object: {{"is_relevant": true/false, "reason": "Your brief reason here."}}
            """
            
            relevance_response = model.generate_content(relevance_prompt)
            
            try:
                # Robust JSON parsing
                json_match = re.search(r'\{.*\}', relevance_response.text, re.DOTALL)
                if not json_match: raise ValueError("No JSON in relevance response.")
                relevance_result = json.loads(json_match.group(0))
                is_relevant = relevance_result.get("is_relevant", False)
                reason = relevance_result.get("reason", "No reason provided.")
                print(f"--- [CACHE CHECK] Gemini decision: Relevant = {is_relevant}. Reason: {reason}")
            except (json.JSONDecodeError, ValueError) as e:
                print(f"--- [CACHE CHECK] ‚ö†Ô∏è Could not parse relevance check response: {e}")
                is_relevant = False

        if is_relevant:
            print("--- [CACHE CHECK] ‚úÖ Using existing report. Skipping new research.")
            st.success(f"üí° Found a relevant report on '{latest_report['topic']}'! Answering from cache.")
            report = latest_report['content']
            print("latest report")
            print(latest_report)
            report_id = latest_report['id']
            GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
            genai.configure(api_key=GEMINI_API_KEY)
            model = genai.GenerativeModel('gemini-1.5-flash-latest')
            answer_prompt = f"""You are a world-class research analyst and communication expert. Your task is to provide the best possible answer to a user's question, using ONLY the provided research report as your source of truth.

            **Your Thought Process (Follow these steps internally):**
            1.  **Analyze the User's Question:** First, understand the *intent* behind the question. Are they asking for:
                - A specific fact or data point?
                - A general summary of a topic?
                - A story, example, or personal experience (anecdote)?
                - The overall sentiment or opinions of the community?
            2.  **Scan the Report for Relevance:** Read through the entire research report and identify the 2-4 most relevant paragraphs, themes, or stories that directly address the user's question.
            3.  **Synthesize and Structure:** Based on the user's intent, synthesize the relevant information into a perfectly structured answer. Do NOT just copy-paste from the report.

            **Response Formatting Rules:**
            - If the user is asking for **facts or data**, provide a direct answer followed by bullet points with the supporting data.
            - If the user is asking for a **summary**, provide a concise paragraph followed by a clear, bulleted list of the key takeaways.
            - If the user is asking for a **story or anecdote**, retell the most relevant story from the report in a narrative format.
            - If the user is asking about **sentiment**, summarize the different viewpoints (e.g., "The community was largely positive, with some expressing concern about X...").
            - **Crucially:** If the report does not contain information to answer the question, you MUST explicitly state: "I'm sorry, but the research report does not contain specific information about that topic." Do not invent information.

            ---
            **<Research_Report>**
            {report}
            **</Research_Report>**
            ---

            **User's Question:** "{question}"

            ---
            **Your Final Answer:**
            """
            
            print("-> Sending advanced Q&A prompt to Gemini...")
            response = model.generate_content(answer_prompt)
            print("-> Gemini response received.")
            print(len(response.text), "characters in the response.")
            final_answer = response.text
            return final_answer

            
        else:
            print("--- [CACHE CHECK] ‚ÑπÔ∏è Existing report is not relevant enough. Starting new research.")
            reddit = praw.Reddit(
            client_id=os.getenv('REDDIT_CLIENT_ID'),
            client_secret=os.getenv('REDDIT_CLIENT_SECRET'),
            user_agent=os.getenv('REDDIT_USER_AGENT', 'Social Media Agent by Faiq'),
            username=os.getenv('REDDIT_USERNAME'),
            password=os.getenv('REDDIT_PASSWORD')
        )
            st.success("‚úÖ Reddit client initialized.")

            # Find relevant subreddits
            with st.spinner("Finding relevant subreddits..."):
                subreddits = find_relevant_subreddits(topic, limit=5)
            if not subreddits:
                return "‚ùå Could not find any relevant subreddits for this topic."
            st.write(f"Found potential subreddits: `{', '.join(subreddits)}`")

            # Search and filter for the best posts
            with st.spinner("Searching for top posts and comments..."):
                top_submissions, top_posts, top_comments = search_and_filter_posts(reddit, subreddits, topic)
            if not any([top_submissions, top_posts, top_comments]):
                return "‚ùå No relevant posts or comments found matching the topic."
            st.write(f"Found {len(top_submissions)} top submissions, {len(top_posts)} top posts, and {len(top_comments)} top comments.")

            # Scrape the validated content
            with st.spinner("Scraping detailed content..."):
                consolidated_data = scrape_validated_posts(top_submissions, top_posts, top_comments)

            raw_report_file = save_raw_data_to_file(consolidated_data, topic)
            print(f"Raw report saved to: {raw_report_file}")
            # Generate the comprehensive report
            with st.spinner("Synthesizing data into a research report... (This may take a moment)"):
                report = generate_report_from_posts(topic, consolidated_data)
                report_file = save_report_to_file(report, topic)
            # NEW: Save the generated report to the database
            print("saving the report to the database...")
            report_id = save_research_report(user_id=user_id, topic=topic, content=report)
            print(f"Report saved with ID: {report_id}")
            st.success("‚úÖ Research report generated and saved.")
            st.success("‚úÖ Research report generated.")
                    # Answer the user's question based on the report
            with st.spinner("Formulating final answer..."):
                GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")


                genai.configure(api_key=GEMINI_API_KEY)
                model = genai.GenerativeModel('gemini-1.5-flash-latest')

                # --- Step 2: The Advanced, Multi-Purpose Prompt ---
                answer_prompt = f"""You are a world-class research analyst and communication expert. Your task is to provide the best possible answer to a user's question, using ONLY the provided research report as your source of truth.

                **Your Thought Process (Follow these steps internally):**
                1.  **Analyze the User's Question:** First, understand the *intent* behind the question. Are they asking for:
                    - A specific fact or data point?
                    - A general summary of a topic?
                    - A story, example, or personal experience (anecdote)?
                    - The overall sentiment or opinions of the community?
                2.  **Scan the Report for Relevance:** Read through the entire research report and identify the 2-4 most relevant paragraphs, themes, or stories that directly address the user's question.
                3.  **Synthesize and Structure:** Based on the user's intent, synthesize the relevant information into a perfectly structured answer. Do NOT just copy-paste from the report.

                **Response Formatting Rules:**
                - If the user is asking for **facts or data**, provide a direct answer followed by bullet points with the supporting data.
                - If the user is asking for a **summary**, provide a concise paragraph followed by a clear, bulleted list of the key takeaways.
                - If the user is asking for a **story or anecdote**, retell the most relevant story from the report in a narrative format.
                - If the user is asking about **sentiment**, summarize the different viewpoints (e.g., "The community was largely positive, with some expressing concern about X...").
                - **Crucially:** If the report does not contain information to answer the question, you MUST explicitly state: "I'm sorry, but the research report does not contain specific information about that topic." Do not invent information.

                ---
                **<Research_Report>**
                {report}
                **</Research_Report>**
                ---

                **User's Question:** "{question}"

                ---
                **Your Final Answer:**
                """
                
                print("-> Sending advanced Q&A prompt to Gemini...")
                response = model.generate_content(answer_prompt)
                print("-> Gemini response received.")
                print(len(response.text), "characters in the response.")
                final_answer = response.text
                save_chat_message(user_id=user_id, role="assistant", content=final_answer, report_id=report_id)
                # THIS EXPANDER WILL NOW ALWAYS BE DISPLAYED
                with st.expander("Click to view the full research report used for this answer"):
                    st.markdown(report)
                if os.path.exists(raw_report_file) and raw_report_file :
                    with open(raw_report_file, "r", encoding="utf-8") as f:
                        report_content = f.read()

                    with st.expander("Click to view the full raw research report used for this answer"):
                        st.markdown(report_content)
                else:
                    st.warning("‚ö†Ô∏è Raw Report file not found or could not be read.")
            

                
            return final_answer
    else:
        print("--- [CACHE CHECK] ‚ÑπÔ∏è there is no existing report making the first one.")
        reddit = praw.Reddit(
        client_id=os.getenv('REDDIT_CLIENT_ID'),
        client_secret=os.getenv('REDDIT_CLIENT_SECRET'),
        user_agent=os.getenv('REDDIT_USER_AGENT', 'Social Media Agent by Faiq'),
        username=os.getenv('REDDIT_USERNAME'),
        password=os.getenv('REDDIT_PASSWORD')
    )
        st.success("‚úÖ Reddit client initialized.")
                # Find relevant subreddits
        with st.spinner("Finding relevant subreddits..."):
            subreddits = find_relevant_subreddits(topic, limit=5)
        if not subreddits:
            return "‚ùå Could not find any relevant subreddits for this topic."
        st.write(f"Found potential subreddits: `{', '.join(subreddits)}`")

        # Search and filter for the best posts
        with st.spinner("Searching for top posts and comments..."):
            top_submissions, top_posts, top_comments = search_and_filter_posts(reddit, subreddits, topic)
        if not any([top_submissions, top_posts, top_comments]):
            return "‚ùå No relevant posts or comments found matching the topic."
        st.write(f"Found {len(top_submissions)} top submissions, {len(top_posts)} top posts, and {len(top_comments)} top comments.")

        # Scrape the validated content
        with st.spinner("Scraping detailed content..."):
            consolidated_data = scrape_validated_posts(top_submissions, top_posts, top_comments)
            raw_report_file = save_raw_data_to_file(consolidated_data, topic)
        # Generate the comprehensive report
        with st.spinner("Synthesizing data into a research report... (This may take a moment)"):
            report = generate_report_from_posts(topic, consolidated_data)
            report_file = save_report_to_file(report, topic)
        # NEW: Save the generated report to the database
        print("saving the report to the database...")
        report_id = save_research_report(user_id=user_id, topic=topic, content=report)
        print(f"Report saved with ID: {report_id}")
        st.success("‚úÖ Research report generated and saved.")
        st.success("‚úÖ Research report generated.")
                # Answer the user's question based on the report
        with st.spinner("Formulating final answer..."):
            GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")


            genai.configure(api_key=GEMINI_API_KEY)
            model = genai.GenerativeModel('gemini-1.5-flash-latest')

            # --- Step 2: The Advanced, Multi-Purpose Prompt ---
            answer_prompt = f"""You are a world-class research analyst and communication expert. Your task is to provide the best possible answer to a user's question, using ONLY the provided research report as your source of truth.

            **Your Thought Process (Follow these steps internally):**
            1.  **Analyze the User's Question:** First, understand the *intent* behind the question. Are they asking for:
                - A specific fact or data point?
                - A general summary of a topic?
                - A story, example, or personal experience (anecdote)?
                - The overall sentiment or opinions of the community?
            2.  **Scan the Report for Relevance:** Read through the entire research report and identify the 2-4 most relevant paragraphs, themes, or stories that directly address the user's question.
            3.  **Synthesize and Structure:** Based on the user's intent, synthesize the relevant information into a perfectly structured answer. Do NOT just copy-paste from the report.

            **Response Formatting Rules:**
            - If the user is asking for **facts or data**, provide a direct answer followed by bullet points with the supporting data.
            - If the user is asking for a **summary**, provide a concise paragraph followed by a clear, bulleted list of the key takeaways.
            - If the user is asking for a **story or anecdote**, retell the most relevant story from the report in a narrative format.
            - If the user is asking about **sentiment**, summarize the different viewpoints (e.g., "The community was largely positive, with some expressing concern about X...").
            - **Crucially:** If the report does not contain information to answer the question, you MUST explicitly state: "I'm sorry, but the research report does not contain specific information about that topic." Do not invent information.

            ---
            **<Research_Report>**
            {report}
            **</Research_Report>**
            ---

            **User's Question:** "{question}"

            ---
            **Your Final Answer:**
            """
            
            print("-> Sending advanced Q&A prompt to Gemini...")
            response = model.generate_content(answer_prompt)
            print("-> Gemini response received.")
            print(len(response.text), "characters in the response.")
            final_answer = response.text
            save_chat_message(user_id=user_id, role="assistant", content=final_answer, report_id=report_id)
            st.info("Displaying the full report below (click to expand).")
            # THIS EXPANDER WILL NOW ALWAYS BE DISPLAYED
            with st.expander("Click to view the full research report used for this answer"):
                st.markdown(report)
            if os.path.exists(raw_report_file) and raw_report_file :
                with open(raw_report_file, "r", encoding="utf-8") as f:
                    report_content = f.read()

                with st.expander("Click to view the full raw research report used for this answer"):
                    st.markdown(report_content)
            else:
                st.warning("‚ö†Ô∏èRaw Report file not found or could not be read.")
                    

        return final_answer
        


def execute_direct_posting_workflow(user_id: str, text_to_post: str) -> str:
    """
    Directly posts user-provided text to social media platforms.
    """
    print("\n" + "="*50)
    print("--- üöÄ WORKFLOW START: Direct Posting ---")
    st.info(f"üì¨ Preparing to post your content directly...")

    # In a real app, you might ask the LLM to generate a title from the text.
    # For now, we'll create a generic one.
    title = f"A new post from {st.session_state.username}"
    
    st.subheader("üìù Content to be Posted")
    st.markdown(f"**Title:** {title}")
    st.markdown(f"**Post Text:**\n\n{text_to_post}")
    
    # Placeholder for image selection if needed in the future
    image_path = None
    
    # Post to platforms
    results = []
    try:
        with st.spinner("Posting to Reddit..."):
            reddit_url = post_to_reddit(title, text_to_post, image_path=image_path)
        results.append(f"‚úÖ Successfully posted to Reddit: {reddit_url}")
    except Exception as e:
        results.append(f"‚ùå Failed to post to Reddit: {e}")
    
    # ... Add Twitter posting logic here ...
    
    return "\n\n".join(results)

def execute_url_posting_workflow(user_id: str, url: str) -> str:
    """
    Handles scraping a URL, generating content, and preparing it for user review.
    IT DOES NOT POST THE CONTENT.
    """
    print("\n" + "="*50)
    print("--- üöÄ WORKFLOW START: URL Content Generation ---")
    st.info(f"üåç Starting content generation from URL: {url}...")
    
    try:
        with st.spinner("Scraping and summarizing content..."):
            formatted_content, raw_response = scrape_and_format_content(url)
        st.success("‚úÖ Content scraped and summarized.")

        with st.spinner("Generating post title and text..."):
            title, generated_text = generate_post_function(formatted_content)
        st.success("‚úÖ Social media post generated.")

        with st.spinner("Finding and selecting the best image..."):
            all_image_urls = extract_images_from_firecrawl(raw_response)
            best_image_url = get_best_image_from_candidates(all_image_urls, generated_text)
        
        # --- NEW: Store the draft in session_state instead of posting ---
        st.session_state.post_draft = {
            "title": title,
            "text": generated_text,
            "image_url": best_image_url
        }
        print("-> Saved generated content as a draft in session state.")
        
        # Create the preview message for the user
        preview_message = f"**Here is the draft I've prepared based on the URL.**\n\n"
        preview_message += f"**Title:** {title}\n\n"
        preview_message += f"**Post Text:**\n{generated_text}\n\n"
        if best_image_url:
            preview_message += f"**Suggested Image:**\n{best_image_url}"
        
        # Save this preview to the chat history
        save_chat_message(user_id=user_id, role="assistant", content=preview_message)
        
        return preview_message

    except Exception as e:
        st.error(f"An error occurred in the URL posting workflow: {e}")
        error_message = f"‚ùå Workflow failed: {e}"
        save_chat_message(user_id=user_id, role="assistant", content=error_message)
        return error_message

def execute_revision_workflow(user_id: str, revision_request: str) -> str:
    """
    Revises the post draft based on user feedback and updates the session state.
    """
    print("\n" + "="*50)
    print("--- üöÄ WORKFLOW START: Post Revision ---")
    st.info(f"‚úçÔ∏è Revising the draft with your feedback: '{revision_request}'...")

    # Check if there is a draft to revise
    if 'post_draft' not in st.session_state or not st.session_state.post_draft:
        return "‚ùå I couldn't find a post draft to revise. Please generate a post from a URL first."

    original_post_text = st.session_state.post_draft['text']

    with st.spinner("Revising the post..."):
        llm = ChatOpenAI(model="gpt-4o", temperature=0.7, openai_api_key=OPENAI_API_KEY)
        revision_prompt = f"""You are a copy editor. Revise the following social media post based on the user's instructions.

        <Original_Post_Text>
        {original_post_text}
        </Original_Post_Text>

        <User_Revision_Request>
        {revision_request}
        </User_Revision_Request>

        Provide ONLY the full, revised post text as your response.
        """
        response = llm.invoke(revision_prompt)
        revised_post_text = response.content.strip()

    # --- NEW: Update the draft in session_state ---
    st.session_state.post_draft['text'] = revised_post_text
    print("-> Updated post draft in session state with revised text.")
    
    st.success("‚úÖ Post draft revised successfully!")
    
    # Create the preview message for the user
    revised_preview = f"**Here is the revised draft:**\n\n"
    revised_preview += f"**Title:** {st.session_state.post_draft['title']}\n\n"
    revised_preview += f"**Post Text:**\n{revised_post_text}\n\n"
    if st.session_state.post_draft['image_url']:
        revised_preview += f"**Suggested Image:**\n{st.session_state.post_draft['image_url']}"
    
    save_chat_message(user_id=user_id, role="assistant", content=revised_preview)
    return revised_preview

def execute_actual_posting(user_id: str, title: str, text: str, image_url: Optional[str]) -> str:
    """
    Takes finalized content and posts it to social media platforms.
    """
    print("\n" + "="*50)
    print("--- üöÄ ACTION: Posting Content ---")
    st.info("üöÄ Posting your approved content now...")
    
    image_path = None
    if image_url:
        try:
            print(f"-> Downloading final image: {image_url}")
            image_path = "final_post_image.jpg"
            img_data = requests.get(image_url).content
            with open(image_path, "wb") as handler:
                handler.write(img_data)
            print("-> Image downloaded successfully.")
        except Exception as e:
            st.warning(f"Could not download the final image. Posting text-only. Error: {e}")
            image_path = None
    
    results = []
    # Post to Reddit
    try:
        with st.spinner("Posting to Reddit..."):
            reddit_url = post_to_reddit(title, text, image_path=image_path)
        results.append(f"‚úÖ Successfully posted to Reddit: {reddit_url}")
    except Exception as e:
        results.append(f"‚ùå Failed to post to Reddit: {e}")

    
    # Clean up the temporary image file
    if image_path and os.path.exists(image_path):
        os.remove(image_path)
    
    final_status = "\n\n".join(results)
    save_chat_message(user_id=user_id, role="assistant", content=final_status)
    return final_status

# ==============================================================================
# --- ROUTER FUNCTION (The Brains of the Operation) ---
# ==============================================================================

def route_user_request(user_prompt: str, chat_history: List[Dict[str, str]]) -> dict:
    """
    Analyzes the user's prompt and chat history to decide which tool to use.
    """
    print(f"\n--- [ROUTER] Analyzing user prompt with chat history...")

    llm = ChatOpenAI(model="gpt-4o", temperature=0)

    formatted_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history])

    router_prompt = f"""You are an intelligent routing agent. Your job is to analyze the latest user prompt in the context of the entire chat history and determine which of the four available tools is appropriate to call.

    **Chat History:**
    <history>
    {formatted_history}
    </history>

    **Available Tools:**
    1. `revise_post`: Use this tool if the user wants to change or edit the most recent assistant message.  
        - Required field: `"revision_request"` (a single string describing all changes, such as: "Change the title to 'New Title' and add a line at the end that says 'Faiq has said all of this.'")

    2. `direct_post`: Use this tool if the user provides full text and explicitly wants to publish it.  
        - Required field: `"text_to_post"` (the full content to post)

    3. `reddit_research`: Use this tool if the user is asking about general Reddit-based questions, public sentiment, or real opinions.  
        - Required fields: `"topic"` and `"question"`

    4. `url_poster`: Use this if the user provides a URL and wants to auto-generate a social media post from it.  
        - Required field: `"url"`

    Respond ONLY with a valid raw JSON object using one of the tool formats below. Do NOT add any explanation or Markdown.

    **Reddit Research Example:**
    {{ "tool": "reddit_research", "args": {{ "topic": "ai jobs germany", "question": "what is the situation of ai job market in germany?" }} }}

    **URL Poster Example:**
    {{ "tool": "url_poster", "args": {{ "url": "https://example.com" }} }}

    **Revise Post Example:**
    {{ "tool": "revise_post", "args": {{ "revision_request": "Change the title to 'AI Trends 2025' and add 'This was written by Faiq.' at the end." }} }}

    **Direct Post Example:**
    {{ "tool": "direct_post", "args": {{ "text_to_post": "Here is the complete post text the user wants to share..." }} }}

    **User Prompt:** "{user_prompt}"
    """


    response = llm.invoke(router_prompt)
    raw_response_content = response.content.strip()
    print(f"--- [ROUTER] Raw LLM response:\n{raw_response_content}\n---")

    try:
        json_match = re.search(r'\{.*\}', raw_response_content, re.DOTALL)
        if not json_match:
            raise ValueError("No JSON object found in LLM response.")

        json_string = json_match.group(0)
        decision = json.loads(json_string)

        # Normalize if "arguments" is used
        if "arguments" in decision and "args" not in decision:
            decision["args"] = decision.pop("arguments")

        # Handle flat cases like { "url": "..." }
        if "tool" not in decision:
            if "url" in decision:
                decision = {
                    "tool": "url_poster",
                    "args": {"url": decision["url"]}
                }
            elif "text_to_post" in decision:
                decision = {
                    "tool": "direct_post",
                    "args": {"text_to_post": decision["text_to_post"]}
                }
            else:
                raise ValueError("Malformed JSON: missing 'tool' or unrecognized structure.")

        tool = decision.get("tool")
        args = decision.get("args", {})

        if not tool or not isinstance(args, dict):
            raise ValueError("Malformed JSON: missing 'tool' or 'args'.")

        # Per-tool validation
        if tool == "reddit_research" and not ("topic" in args and "question" in args):
            raise ValueError("Missing 'topic' or 'question' for reddit_research.")
        if tool == "url_poster" and "url" not in args:
            raise ValueError("Missing 'url' for url_poster.")
        if tool == "revise_post" and "revision_request" not in args:
            raise ValueError("Missing 'revision_request' for revise_post.")
        if tool == "direct_post" and "text_to_post" not in args:
            raise ValueError("Missing 'text_to_post' for direct_post.")

        print(f"--- [ROUTER] ‚úÖ Decision: tool = '{tool}', args = {args}")
        return decision

    except (json.JSONDecodeError, ValueError) as e:
        print(f"--- [ROUTER] ‚ùå Parsing/validation error: {e}")
        return {"tool": "error", "args": {"reason": f"Could not understand the request: {e}"}}
    except Exception as e:
        print(f"--- [ROUTER] ‚ùå Unexpected error: {e}")
        return {"tool": "error", "args": {"reason": f"An internal error occurred: {e}"}}


# ==============================================================================
# --- UTILITY AND WORKER FUNCTIONS ---
# (Place all your other functions like find_relevant_subreddits, generate_post_function, etc. here)
# ...
# ==============================================================================

# ==============================================================================
# --- STREAMLIT FRONTEND ---
# ==============================================================================
# In your app.py

def main():
    st.set_page_config(page_title="Social Media Agent", layout="wide")
    st.title("üöÄ Social Media Content Agent")

    # --- Step 1: Initialize Session State ---
    # We add 'post_draft' to hold content waiting for user approval.
    if 'logged_in' not in st.session_state:
        st.session_state.logged_in = False
        st.session_state.user_id = None
        st.session_state.username = None
        st.session_state.messages = []
        st.session_state.post_draft = None # Will hold dict: {title, text, image_url}

    # --- Step 2: Show Login/Signup UI if not logged in ---
    if not st.session_state.logged_in:
        st.header("Welcome!")
        login_tab, signup_tab = st.tabs(["Login", "Sign Up"])

        with login_tab:
            with st.form("login_form"):
                login_username = st.text_input("Username", key="login_user")
                login_password = st.text_input("Password", type="password", key="login_pass")
                login_button = st.form_submit_button("Login")
                if login_button:
                    if login_username and login_password:
                        with st.spinner("Verifying..."):
                            user_data = verify_user(login_username, login_password)
                            if user_data:
                                st.session_state.logged_in = True
                                st.session_state.user_id = user_data['id']
                                st.session_state.username = login_username
                                st.session_state.messages = get_chat_history(user_data['id'])
                                st.success("Logged in successfully!")
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.error("Invalid username or password.")
                    else:
                        st.warning("Please enter both username and password.")

        with signup_tab:
            with st.form("signup_form"):
                signup_username = st.text_input("Choose a Username", key="signup_user")
                signup_password = st.text_input("Choose a Password", type="password", key="signup_pass")
                signup_button = st.form_submit_button("Sign Up")
                if signup_button:
                    if signup_username and signup_password:
                        try:
                            with st.spinner("Creating account..."):
                                new_user = create_user(signup_username, signup_password)
                                st.session_state.logged_in = True
                                st.session_state.user_id = new_user['id']
                                st.session_state.username = signup_username
                                st.session_state.messages = []
                                st.success("Account created! You are now logged in.")
                                time.sleep(1)
                                st.rerun()
                        except ValueError as e:
                            st.error(e)
                        except Exception as e:
                            st.error(f"An error occurred: {e}")
                    else:
                        st.warning("Please enter both a username and password.")
    
    # --- Step 3: Show the Main Chat Application if logged in ---
    else:
        st.sidebar.header(f"Welcome, {st.session_state.username}!")
        if st.sidebar.button("Logout"):
            for key in list(st.session_state.keys()): del st.session_state[key]
            st.rerun()

        st.write("Your AI assistant for content research and posting.")

        # Display chat history
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # --- Human-in-the-Loop (HITL) Block for Posting ---
        # This block is the core of the new functionality. It appears when a draft is ready.
        if st.session_state.get('post_draft'):
            draft = st.session_state.post_draft
            with st.chat_message("assistant"):
                with st.container(border=True):
                    st.subheader("üìù Draft Ready for Review")
                    st.markdown(f"**Title:** {draft['title']}")
                    st.markdown(f"**Post Text:**\n{draft['text']}")
                    if draft.get('image_url'):
                        st.image(draft['image_url'], caption="Suggested Image")
                    
                    st.markdown("---")
                    st.write("You can ask for revisions, or use the buttons below.")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("‚úÖ Post Now", key="post_now", use_container_width=True, type="primary"):
                            with st.spinner("üöÄ Posting to reddit"):
                                status = execute_actual_posting(
                                    user_id=st.session_state.user_id,
                                    title=draft['title'], text=draft['text'],
                                    image_url=draft.get('image_url')
                                )
                            st.success("Posting action complete!")
                            st.session_state.post_draft = None # Clear the draft after posting
                            st.session_state.messages.append({"role": "assistant", "content": status})
                            st.rerun()

                    with col2:
                        if st.button("üóëÔ∏è Discard Draft", key="discard_draft", use_container_width=True):
                            st.session_state.post_draft = None
                            discard_message = "Draft discarded."
                            save_chat_message(st.session_state.user_id, "assistant", discard_message)
                            st.session_state.messages.append({"role": "assistant", "content": discard_message})
                            st.rerun()

        # Get new user input
        if user_prompt := st.chat_input("What would you like to do?"):
            # When the user sends a new prompt, save it and display it immediately
            save_chat_message(user_id=st.session_state.user_id, role="user", content=user_prompt)
            st.session_state.messages.append({"role": "user", "content": user_prompt})
            
            # If the user types a new prompt while a draft is waiting, we assume they
            # want to start a new task. Clear the old draft.
            if st.session_state.get('post_draft'):
                st.session_state.post_draft = None
            
            # Rerun to show the user's message immediately before processing
            st.rerun()

    # --- Assistant Response Logic ---
    # This block runs only if there's a new user message that hasn't been responded to.
    if st.session_state.get('logged_in') and st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        user_prompt = st.session_state.messages[-1]["content"]
        
        with st.chat_message("assistant"):
            with st.spinner("üß† Analyzing your request..."):
                # Pass the history *before* the current prompt for context
                decision = route_user_request(user_prompt, st.session_state.messages[:-1])
                tool_to_call = decision.get("tool")
                args = decision.get("args", {})

            # Execute the chosen workflow
            response_content = ""
            if tool_to_call == "reddit_research":
                topic, question = args.get("topic"), args.get("question")
                if topic and question:
                    response_content = execute_reddit_research_workflow(st.session_state.user_id, topic, question)
                else:
                    response_content = "I need both a topic and a question for Reddit research."

            elif tool_to_call == "url_poster": # This now just generates a draft
                url = args.get("url")
                if url:
                    response_content = execute_url_posting_workflow(st.session_state.user_id, url)
                else:
                    response_content = "I need a URL to post about."

            elif tool_to_call == "revise_post": # This revises the draft in session_state
                revision_request = args.get("revision_request")
                if revision_request:
                    response_content = execute_revision_workflow(st.session_state.user_id, revision_request)
                else:
                    response_content = "I understood you want to revise, but please provide specific instructions."

            elif tool_to_call == "direct_post": # Prepares a draft from user text
                text_to_post = args.get("text_to_post")
                if text_to_post:
                    response_content = execute_direct_posting_workflow(st.session_state.user_id, text_to_post)
                else:
                    response_content = "I need the exact text you want me to post."
            
            else: # Handles router errors
                response_content = args.get("reason", "I'm sorry, I couldn't understand that request.")
                save_chat_message(user_id=st.session_state.user_id, role="assistant", content=response_content)
            
            # The workflow functions should handle their own database saving.
            # We now just update the UI state.
            st.session_state.messages.append({"role": "assistant", "content": response_content})
            st.rerun()

# --- Entry Point ---
if __name__ == "__main__":
    # Ensure all your helper/worker functions (like `route_user_request`, `execute_..._workflow`, etc.)
    # are defined in this file *before* this main() function.
    main()